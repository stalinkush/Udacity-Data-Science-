{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Errors\n",
    "\n",
    "There are two datasets available in this dataset that represent two of the examples you have seen in this lesson.  \n",
    "\n",
    "One dataset is based on the parachute example, and the second is the judicial datast.  None of the dataset in these datasets pertains to real people.\n",
    "\n",
    "Use the questions below to assist in answering the quiz questions at the bottom of this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "jud_data = pd.read_csv('judicial_dataset_predictions.csv')\n",
    "par_data = pd.read_csv('parachute_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>defendant_id</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22574</td>\n",
       "      <td>innocent</td>\n",
       "      <td>innocent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35637</td>\n",
       "      <td>innocent</td>\n",
       "      <td>innocent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39919</td>\n",
       "      <td>innocent</td>\n",
       "      <td>innocent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29610</td>\n",
       "      <td>guilty</td>\n",
       "      <td>guilty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38273</td>\n",
       "      <td>innocent</td>\n",
       "      <td>innocent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   defendant_id    actual predicted\n",
       "0         22574  innocent  innocent\n",
       "1         35637  innocent  innocent\n",
       "2         39919  innocent  innocent\n",
       "3         29610    guilty    guilty\n",
       "4         38273  innocent  innocent"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of the Dataset is (7283, 3)\n"
     ]
    }
   ],
   "source": [
    "print('The Shape of the Dataset is {}'.format(jud_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parachute_id</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3956</td>\n",
       "      <td>opens</td>\n",
       "      <td>opens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2147</td>\n",
       "      <td>opens</td>\n",
       "      <td>opens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>opens</td>\n",
       "      <td>opens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8325</td>\n",
       "      <td>opens</td>\n",
       "      <td>opens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6598</td>\n",
       "      <td>opens</td>\n",
       "      <td>opens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parachute_id actual predicted\n",
       "0          3956  opens     opens\n",
       "1          2147  opens     opens\n",
       "2          2024  opens     opens\n",
       "3          8325  opens     opens\n",
       "4          6598  opens     opens"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` Above, you can see the actual and predicted columns for each of the datasets.  Using the **jud_data**, find the proportion of errors for the dataset, and furthermore, the percentage of errors of each type.  Use the results to answer the questions in quiz 1 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different Types of Errors When everyone is assumed to be innocent\n",
      "\n",
      " The Percentage of Errors: 0.0422 \n",
      " The Percentage of Type 1 Errors: 0.0015 \n",
      " The Percentage of Type 2 Errors: 0.0406\n"
     ]
    }
   ],
   "source": [
    "#Total percentage Error\n",
    "wrong = jud_data.query('actual != predicted').shape[0]\n",
    "total = jud_data.shape[0]\n",
    "\n",
    "error_per = (wrong / total) \n",
    "\n",
    "#Type 1 Error when every one is assumped to be innonent \n",
    "type1 = jud_data.query('actual == \"innocent\" and predicted == \"guilty\"').shape[0]\n",
    "type1_per = (type1 / total) \n",
    "\n",
    "#Type 2 Error\n",
    "type2 = jud_data.query('actual == \"guilty\" and predicted == \"innocent\"').shape[0]\n",
    "type2_per = (type2 / total) \n",
    "\n",
    "print('Different Types of Errors When everyone is assumed to be innocent\\n')\n",
    "print(' The Percentage of Errors: {} \\n The Percentage of Type 1 Errors: {} \\n The Percentage of Type 2 Errors: {}'\\\n",
    "      .format(round(error_per, 4), round(type1_per, 4), round(type2_per, 4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Type 1 Error if everyone is predicted to be guilty\n",
    "#type1 = jud_data.query('actual == \"guilty\"').shape[0]\n",
    "#type1_per = (type1 / total) \n",
    "\n",
    "#Type 2 Error\n",
    "#type2 = jud_data.query('actual == \"innocent\"').shape[0]\n",
    "#type2_per = (type2 / total) \n",
    "\n",
    "#print('Different Types of Errors When everyone is assumned to be guilty\\n')\n",
    "#print(' The Percentage of Type 1 Errors: {}\\n The Percentage of Type 2 Errors: {}'\\\n",
    "#    .format(round(type1_per, 4), round(type2_per, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Above, you can see the actual and predicted columns for each of the datasets.  Using the **par_data**, find the proportion of errors for the dataset, and furthermore, the percentage of errors of each type.  Use the results to answer the questions in quiz 2 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   parachute_id actual predicted\n",
      "0          3956  opens     opens\n",
      "1          2147  opens     opens\n",
      "2          2024  opens     opens\n",
      "3          8325  opens     opens\n",
      "4          6598  opens     opens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5829, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(par_data.head())\n",
    "\n",
    "par_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different Types of Errors\n",
      "\n",
      "The Total Percentage Error: 0.039972551037913875\n",
      " The Percentage of Type 1 Error: 0.03980099502487562\n",
      " The Percentage of Type 2 Errors: 0.00017155601303825698\n"
     ]
    }
   ],
   "source": [
    "#Error Percentage\n",
    "error = par_data.query('actual != predicted').shape[0]\n",
    "total = par_data.shape[0]\n",
    "\n",
    "error_per = (error / total)\n",
    "\n",
    "#Type 1 Error\n",
    "type1 = par_data.query('actual == \"opens\" and predicted ==\"fails\"').shape[0]\n",
    "type1_err = (type1 / total)\n",
    "\n",
    "#Type 2 Error\n",
    "type2 = par_data.query('predicted == \"opens\" and actual == \"fails\"').shape[0]\n",
    "type2_err = (type2 / total)\n",
    "\n",
    "print('Different Types of Errors\\n')\n",
    "print('The Total Percentage Error: {}\\n The Percentage of Type 1 Error: {}\\n The Percentage of Type 2 Errors: {}'\\\n",
    "     .format(error_per, type1_err, type2_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Type 1 Error When every parachute is predicted not to open\n",
    "#type1 = par_data.query('predicted == \"opens\" and actual == \"fails\"').shape[0]\n",
    "#type1_err = (type1 / total)\n",
    "\n",
    "#Type 2 Errors\n",
    "#type2 = par_data.query('predicted == \"fails\" and actual == \"opens\"').shape[0]\n",
    "#type2_err = (type2 / total)\n",
    "\n",
    "#print('The Errors When Every Parachute is assumed not to open\\n')\n",
    "#print(' Type 1 Error: {}\\n Type 2 Error: {}'.format(type1_err, type2_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
